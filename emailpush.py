#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fund-NAV harvester v0.9.4 (Modified to process ALL emails when requested)
Streamlit Enhanced Version - Chinese UI - With Process All Emails feature
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Streamlit UI for interaction and display (Chinese).
2. IMAP login (163.com, ID handshake)
3. Read last run timestamp (for incremental processing).
4. Option to process new emails since last run, or ALL emails in inbox.
5. On button click, for each selected message:
 â€¢ capture subject + sender + full body text
 â€¢ capture every attachment (any filename)
 â€¢ send âŸ¨subject + body + attachment textâŸ© to GLM-Z1-Flash
6. Parse LLM's JSON response & write rows â†’ å¹´-æœˆ-æ—¥ åŸºé‡‘å‡€å€¼.xlsx (local save & download)
7. Save current run timestamp.
"""
import streamlit as st
import re, json, tempfile, pathlib, datetime, contextlib, io, warnings
from imapclient import IMAPClient # type: ignore
import pyzmail, pandas as pd, requests # type: ignore
import email
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# Optional, nicer HTML-to-text if bs4 is around
try:
    from bs4 import BeautifulSoup # type: ignore
    def html2text(html:str)->str:
        return BeautifulSoup(html, "html.parser").get_text("\n")
except ImportError:
    def html2text(html:str)->str:
        return re.sub(r"<[^>]+>", "", html)

warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")
warnings.filterwarnings("ignore", category=SyntaxWarning, module="pyzmail.utils")
warnings.filterwarnings("ignore", category=SyntaxWarning, module="pyzmail.parse")

# â”€â”€â”€ creds & endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IMAP_HOST = "imap.163.com"
EMAIL_USER = "zhanluekehu@163.com" # è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…é‚®ç®±
EMAIL_PWD = "DRqdN38whrnCFPGx" # è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…163é‚®ç®±åº”ç”¨æˆæƒç 
GLM_KEY = "afe7583d73c9d3948f60230e79e08151.Z9HPB84mxuC31DeK" # è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…GLM API Key
GLM_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
MODEL = "glm-z1-flash" # æˆ–è€…æ‚¨åå¥½çš„æ¨¡å‹ï¼Œå¦‚ "glm-4", "glm-3-turbo"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TODAY = datetime.date.today().strftime("%Y-%m-%d")
XLSX = f"{TODAY} åŸºé‡‘å‡€å€¼.xlsx"
SHEET = TODAY
COLS = ["æ—¥æœŸ","åŸºé‡‘åç§°","åŸºé‡‘ä»£ç ","å•ä½å‡€å€¼","ç´¯è®¡å‡€å€¼",
        "åŸé‚®ä»¶å","å‘ä»¶äºº","å‘ä»¶æœºæ„"]

# â”€â”€â”€ Timestamp logging for incremental processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_DIR = pathlib.Path("log")
LAST_RUN_FILE = LOG_DIR / "last_run.txt"
DATETIME_FORMAT = "%Y-%m-%d %H:%M:%S"

# Initialize session state variables
if 'processing_log' not in st.session_state:
    st.session_state.processing_log = []
if 'processed_df' not in st.session_state:
    st.session_state.processed_df = None
if 'run_summary' not in st.session_state:
    st.session_state.run_summary = {}

def append_log(message, level="info"):
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    st.session_state.processing_log.append(f"[{timestamp}] {message}")

def get_last_run_datetime() -> datetime.datetime | None:
    if not LAST_RUN_FILE.exists():
        append_log("æœªæ‰¾åˆ°ä¸Šæ¬¡è¿è¡Œæ—¶é—´æˆ³æ–‡ä»¶ã€‚å°†ä½¿ç”¨é»˜è®¤æ—¶é—´çª—å£è¿›è¡Œå¤„ç†ã€‚", "info")
        return None
    try:
        with open(LAST_RUN_FILE, 'r', encoding='utf-8') as f:
            timestamp_str = f.read().strip()
            return datetime.datetime.strptime(timestamp_str, DATETIME_FORMAT)
    except Exception as e:
        append_log(f"è¯»å–ä¸Šæ¬¡è¿è¡Œæ—¶é—´æˆ³æ—¶å‡ºé”™: {e}", "error")
        return None

def save_last_run_datetime():
    LOG_DIR.mkdir(exist_ok=True)
    current_time = datetime.datetime.now().strftime(DATETIME_FORMAT)
    try:
        with open(LAST_RUN_FILE, 'w', encoding='utf-8') as f:
            f.write(current_time)
        append_log(f"å·²ä¿å­˜è¿è¡Œæ—¶é—´æˆ³: {current_time}", "info")
    except Exception as e:
        append_log(f"ä¿å­˜è¿è¡Œæ—¶é—´æˆ³æ—¶å‡ºé”™: {e}", "error")

def call_glm_api(prompt_text: str) -> dict:
    """è°ƒç”¨ GLM API å¹¶è¿”å›è§£æåçš„ JSON å“åº”"""
    headers = {
        "Authorization": f"Bearer {GLM_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": MODEL,
        "messages": [
            {
                "role": "user", 
                "content": prompt_text
            }
        ],
        "temperature": 0.1,
        "max_tokens": 2000
    }
    
    try:
        response = requests.post(GLM_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            
            # å°è¯•è§£æJSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                append_log("APIå“åº”ä¸­æœªæ‰¾åˆ°JSONæ ¼å¼æ•°æ®", "warning")
                return {}
        else:
            append_log("APIå“åº”æ ¼å¼å¼‚å¸¸", "error")
            return {}
            
    except requests.exceptions.RequestException as e:
        append_log(f"APIè¯·æ±‚å¤±è´¥: {e}", "error")
        return {}
    except json.JSONDecodeError as e:
        append_log(f"JSONè§£æå¤±è´¥: {e}", "error")
        return {}

def extract_email_content(msg_data):
    """æå–é‚®ä»¶å†…å®¹å’Œé™„ä»¶"""
    try:
        msg = pyzmail.PyzMessage.factory(msg_data[b'BODY[]'])
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        subject = msg.get_subject() or "æ— ä¸»é¢˜"
        sender = msg.get_addresses('from')[0][1] if msg.get_addresses('from') else "æœªçŸ¥å‘ä»¶äºº"
        
        # æå–æ­£æ–‡
        body_text = ""
        if msg.text_part is not None:
            body_text = msg.text_part.get_payload().decode(msg.text_part.charset or 'utf-8', errors='ignore')
        elif msg.html_part is not None:
            html_content = msg.html_part.get_payload().decode(msg.html_part.charset or 'utf-8', errors='ignore')
            body_text = html2text(html_content)
        
        # æå–é™„ä»¶å†…å®¹
        attachment_texts = []
        for mailpart in msg.mailparts:
            if mailpart.is_attachment:
                try:
                    att_content = mailpart.get_payload()
                    if isinstance(att_content, bytes):
                        # å°è¯•è§£ç ä¸ºæ–‡æœ¬
                        try:
                            att_text = att_content.decode('utf-8', errors='ignore')
                            attachment_texts.append(f"é™„ä»¶å†…å®¹:\n{att_text}")
                        except:
                            attachment_texts.append(f"é™„ä»¶: {mailpart.filename} (äºŒè¿›åˆ¶æ–‡ä»¶)")
                    else:
                        attachment_texts.append(f"é™„ä»¶å†…å®¹:\n{att_content}")
                except Exception as e:
                    append_log(f"å¤„ç†é™„ä»¶æ—¶å‡ºé”™: {e}", "warning")
        
        return {
            'subject': subject,
            'sender': sender,
            'body': body_text,
            'attachments': attachment_texts
        }
        
    except Exception as e:
        append_log(f"è§£æé‚®ä»¶æ—¶å‡ºé”™: {e}", "error")
        return None

def fetch_emails(process_all=False):
    """è·å–é‚®ä»¶åˆ—è¡¨"""
    try:
        with IMAPClient(IMAP_HOST) as client:
            client.login(EMAIL_USER, EMAIL_PWD)
            client.select_folder('INBOX')
            
            if process_all:
                # å¤„ç†æ‰€æœ‰é‚®ä»¶
                append_log("æ­£åœ¨è·å–æ”¶ä»¶ç®±ä¸­çš„æ‰€æœ‰é‚®ä»¶...", "info")
                messages = client.search()
                append_log(f"æ‰¾åˆ° {len(messages)} å°é‚®ä»¶", "info")
            else:
                # å¢é‡å¤„ç†ï¼šåªå¤„ç†æ–°é‚®ä»¶
                last_run = get_last_run_datetime()
                if last_run:
                    # ä»ä¸Šæ¬¡è¿è¡Œæ—¶é—´å¼€å§‹
                    since_date = last_run.date()
                    append_log(f"æ­£åœ¨è·å–è‡ª {since_date} ä»¥æ¥çš„æ–°é‚®ä»¶...", "info")
                else:
                    # é»˜è®¤å¤„ç†æœ€è¿‘30å¤©
                    since_date = datetime.date.today() - datetime.timedelta(days=30)
                    append_log(f"æ­£åœ¨è·å–æœ€è¿‘30å¤©çš„é‚®ä»¶ (è‡ª {since_date})...", "info")
                
                messages = client.search(['SINCE', since_date])
                append_log(f"æ‰¾åˆ° {len(messages)} å°æ–°é‚®ä»¶", "info")
            
            if not messages:
                append_log("æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„é‚®ä»¶", "info")
                return []
            
            # è·å–é‚®ä»¶å†…å®¹
            processed_emails = []
            for i, msg_id in enumerate(messages):
                try:
                    append_log(f"æ­£åœ¨å¤„ç†é‚®ä»¶ {i+1}/{len(messages)}", "info")
                    msg_data = client.fetch([msg_id], ['BODY[]'])
                    
                    email_content = extract_email_content(msg_data[msg_id])
                    if email_content:
                        processed_emails.append(email_content)
                        
                except Exception as e:
                    append_log(f"å¤„ç†é‚®ä»¶ {msg_id} æ—¶å‡ºé”™: {e}", "error")
                    continue
            
            return processed_emails
            
    except Exception as e:
        append_log(f"è¿æ¥é‚®ç®±å¤±è´¥: {e}", "error")
        return []

def process_email_with_llm(email_content):
    """ä½¿ç”¨LLMå¤„ç†å•å°é‚®ä»¶"""
    prompt = f"""
è¯·åˆ†æä»¥ä¸‹é‚®ä»¶å†…å®¹ï¼Œæå–åŸºé‡‘å‡€å€¼ä¿¡æ¯ã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š

é‚®ä»¶ä¸»é¢˜: {email_content['subject']}
å‘ä»¶äºº: {email_content['sender']}
é‚®ä»¶æ­£æ–‡:
{email_content['body']}

é™„ä»¶å†…å®¹:
{chr(10).join(email_content['attachments'])}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "funds": [
        {{
            "date": "YYYY-MM-DD",
            "fund_name": "åŸºé‡‘åç§°",
            "fund_code": "åŸºé‡‘ä»£ç ",
            "unit_nav": "å•ä½å‡€å€¼",
            "cumulative_nav": "ç´¯è®¡å‡€å€¼"
        }}
    ]
}}

å¦‚æœé‚®ä»¶ä¸­æ²¡æœ‰åŸºé‡‘å‡€å€¼ä¿¡æ¯ï¼Œè¯·è¿”å›ç©ºçš„fundsæ•°ç»„ã€‚
"""
    
    result = call_glm_api(prompt)
    return result.get('funds', [])

def main():
    st.set_page_config(page_title="åŸºé‡‘å‡€å€¼é‡‡é›†å™¨", layout="wide")
    
    st.title("ğŸ¦ åŸºé‡‘å‡€å€¼é‡‡é›†å™¨")
    st.markdown("è‡ªåŠ¨ä»é‚®ä»¶ä¸­æå–åŸºé‡‘å‡€å€¼ä¿¡æ¯")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    with st.expander("ğŸ“§ é‚®ç®±é…ç½®ä¿¡æ¯"):
        st.info(f"é‚®ç®±: {EMAIL_USER}")
        st.info(f"IMAPæœåŠ¡å™¨: {IMAP_HOST}")
        
        last_run = get_last_run_datetime()
        if last_run:
            st.success(f"ä¸Šæ¬¡è¿è¡Œæ—¶é—´: {last_run.strftime(DATETIME_FORMAT)}")
        else:
            st.warning("è¿™æ˜¯é¦–æ¬¡è¿è¡Œ")
    
    # æ“ä½œæŒ‰é’®
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ”„ å¤„ç†æ–°é‚®ä»¶", type="primary"):
            st.session_state.processing_log = []
            st.session_state.processed_df = None
            st.session_state.run_summary = {}
            
            append_log("å¼€å§‹å¤„ç†æ–°é‚®ä»¶...", "info")
            emails = fetch_emails(process_all=False)
            
            if emails:
                process_emails(emails)
            else:
                st.warning("æ²¡æœ‰æ‰¾åˆ°æ–°é‚®ä»¶éœ€è¦å¤„ç†")
    
    with col2:
        if st.button("ğŸ“§ å¤„ç†æ‰€æœ‰é‚®ä»¶", type="secondary"):
            st.session_state.processing_log = []
            st.session_state.processed_df = None
            st.session_state.run_summary = {}
            
            append_log("å¼€å§‹å¤„ç†æ‰€æœ‰é‚®ä»¶...", "info")
            emails = fetch_emails(process_all=True)  # å…³é”®ä¿®æ”¹ï¼šä¼ å…¥ process_all=True
            
            if emails:
                process_emails(emails)
            else:
                st.warning("æ”¶ä»¶ç®±ä¸­æ²¡æœ‰æ‰¾åˆ°é‚®ä»¶")
    
    with col3:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ—¥å¿—"):
            st.session_state.processing_log = []
            st.session_state.processed_df = None
            st.session_state.run_summary = {}
            st.rerun()
    
    # æ˜¾ç¤ºå¤„ç†æ—¥å¿—
    if st.session_state.processing_log:
        st.subheader("ğŸ“‹ å¤„ç†æ—¥å¿—")
        log_container = st.container()
        with log_container:
            for log_entry in st.session_state.processing_log[-20:]:  # åªæ˜¾ç¤ºæœ€è¿‘20æ¡
                st.text(log_entry)
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if st.session_state.processed_df is not None:
        st.subheader("ğŸ“Š å¤„ç†ç»“æœ")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if st.session_state.run_summary:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("å¤„ç†é‚®ä»¶æ•°", st.session_state.run_summary.get('total_emails', 0))
            with col2:
                st.metric("æˆåŠŸè§£æ", st.session_state.run_summary.get('successful_parses', 0))
            with col3:
                st.metric("æå–åŸºé‡‘æ•°", st.session_state.run_summary.get('total_funds', 0))
            with col4:
                st.metric("å¤„ç†æ—¶é—´", f"{st.session_state.run_summary.get('processing_time', 0):.1f}ç§’")
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.dataframe(st.session_state.processed_df, use_container_width=True)
        
        # ä¸‹è½½æŒ‰é’®
        if not st.session_state.processed_df.empty:
            csv = st.session_state.processed_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                data=csv.encode('utf-8-sig'),
                file_name=f"{TODAY}_åŸºé‡‘å‡€å€¼.csv",
                mime="text/csv"
            )

def process_emails(emails):
    """å¤„ç†é‚®ä»¶åˆ—è¡¨"""
    start_time = datetime.datetime.now()
    all_funds = []
    successful_parses = 0
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, email_content in enumerate(emails):
        progress = (i + 1) / len(emails)
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨å¤„ç†é‚®ä»¶ {i+1}/{len(emails)}: {email_content['subject'][:50]}...")
        
        append_log(f"å¤„ç†é‚®ä»¶: {email_content['subject']}", "info")
        
        try:
            funds = process_email_with_llm(email_content)
            if funds:
                successful_parses += 1
                for fund in funds:
                    fund_row = {
                        "æ—¥æœŸ": fund.get("date", ""),
                        "åŸºé‡‘åç§°": fund.get("fund_name", ""),
                        "åŸºé‡‘ä»£ç ": fund.get("fund_code", ""),
                        "å•ä½å‡€å€¼": fund.get("unit_nav", ""),
                        "ç´¯è®¡å‡€å€¼": fund.get("cumulative_nav", ""),
                        "åŸé‚®ä»¶å": email_content['subject'],
                        "å‘ä»¶äºº": email_content['sender'],
                        "å‘ä»¶æœºæ„": email_content['sender'].split('@')[-1] if '@' in email_content['sender'] else ""
                    }
                    all_funds.append(fund_row)
                    
                append_log(f"æˆåŠŸæå– {len(funds)} ä¸ªåŸºé‡‘ä¿¡æ¯", "info")
            else:
                append_log("æœªæ‰¾åˆ°åŸºé‡‘å‡€å€¼ä¿¡æ¯", "warning")
                
        except Exception as e:
            append_log(f"å¤„ç†é‚®ä»¶æ—¶å‡ºé”™: {e}", "error")
    
    # åˆ›å»ºDataFrame
    if all_funds:
        df = pd.DataFrame(all_funds)
        st.session_state.processed_df = df
        
        # ä¿å­˜åˆ°Excelæ–‡ä»¶
        try:
            df.to_excel(XLSX, sheet_name=SHEET, index=False)
            append_log(f"ç»“æœå·²ä¿å­˜åˆ° {XLSX}", "info")
        except Exception as e:
            append_log(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}", "error")
    else:
        st.session_state.processed_df = pd.DataFrame(columns=COLS)
    
    # ä¿å­˜è¿è¡Œæ—¶é—´æˆ³
    save_last_run_datetime()
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    end_time = datetime.datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    
    st.session_state.run_summary = {
        'total_emails': len(emails),
        'successful_parses': successful_parses,
        'total_funds': len(all_funds),
        'processing_time': processing_time
    }
    
    progress_bar.progress(1.0)
    status_text.text("å¤„ç†å®Œæˆï¼")
    
    append_log(f"å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(emails)} å°é‚®ä»¶ï¼ŒæˆåŠŸè§£æ {successful_parses} å°ï¼Œæå– {len(all_funds)} ä¸ªåŸºé‡‘ä¿¡æ¯", "info")

if __name__ == "__main__":
    main()
